{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping with Python\n",
    "\n",
    "Python is a handy programming language, with some excellent tools for handling scraping projects and also something called BeautifulSoup, which will make you feel like a moron every time you have to type stuff like soup.beautify. We'll try a different tool here and show you how to get started.\n",
    "\n",
    "We're going to assume you're using some flavor of Python 3 here. If you've downloaded this from https://github.com/PalmBeachPost/nicar19scraping , you'll want to make sure you have dependencies -- the modules Python needs to do everything here -- installed.\n",
    "\n",
    "If you're in NICAR ***************************************************************************************\n",
    "\n",
    "If you're using the git repo and looking at this:\n",
    "_pip install -r requirements.txt_ should be reasonably safe.\n",
    "\n",
    "Then:\n",
    "_jupyter notebook_\n",
    "\n",
    "Your web browser should open up now, and you'll see a list of files. The complete tutorial is available locally as *************. The starter shell is ************. And soon you'll see what page to open."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe, orient, decide, act\n",
    "\n",
    "Before you start any scraping task, you'll want to invest a chunk of time into figuring out what you actually have to work with. \n",
    "\n",
    "A simple story: I thought I was going to have to write a scraper, but then the search page I was looking at had an export button that made a nice file that Excel opened up. It looked great, all the same text that was on my screen. I figured out how to dynamically generate that export button link so I could run it on a regular basis and schedule it.\n",
    "\n",
    "Problem was, it really had all the __text__ on my screen -- like the date of a case, the name of the person, the outcome of the investigation. What the export didn't have was critical and not immediately : A link from the case number to the actual paperwork supporting the case. The exported file was missing something that was absolutely critical.\n",
    "\n",
    "So, let's look at what we have to work with. Because of that earlier command -- _python -m http.server_ -- you should have a little web server running already. Let's go to a particular file. Click this link to open it in your browser.\n",
    "\n",
    "http://localhost/www.tdcj.texas.gov/death_row/dr_executed_offenders.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a localized partial copy of a Texas Department of Criminal Justice site, showing \"Executed offenders\" -- people put to death by the state. They seem to be numbered in order, with the newest executions first, and 558 total. If you scroll down, you'll see these go back to very late 1982, meaning we're looking at about 36 years to get 558 executions.\n",
    "\n",
    "Another thing to notice: There's no pagination. There's no \"page 1 of 26\" here. That makes life much easier.\n",
    "\n",
    "When you actually scrape your data, you can start running your own analysis. As you look, though, maybe scribble some notes of things you want think about looking analyzing from this.\n",
    "\n",
    "![Executed offender page\"](support/mainpage.png \"Main executed offender page\")\n",
    "\n",
    "On the main page, you see things like first name, last name, race, gender, age and TDCJ number. The page is from the Texas Department of Criminal Justice, or TDCJ. This is an inmate number -- a unqiue identifier.\n",
    "\n",
    "The newest executee is listed as Braziel, Jr., Alvin. Leave your cursor over the \"Offender Information\" link for Braziel and your browser, in the bottom-left corner, will show you it's http://localhost/www.tdcj.texas.gov/death_row/dr_info/brazielalvin.html . This is a good sign; it's not _javascript:something_. You can work with this. Let's hit that link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there's a bit more of a biography, more demographic details, and a description of an awful crime. Important to note: On the previous page he was \"Braziel, Jr.\" and \"Alvin\". Here, we see the name is no longer broken up but is formatted differently with more information: \"Braziel, Alvin Avon Jr.\" all at once.\n",
    "\n",
    "### What are we trying to scrape here?\n",
    "###### Where are we going, and why are we in this handbasket?\n",
    "\n",
    "Well, you may not always know what you're going to want intially. Almost anything involving death penalty cases, you probably want the demographic information. And you probably want the history of the case. And you probably want the final statement. And Texas may keep the last meal here. So it's consult with Stephen Colbert about where to start:\n",
    "\n",
    "![Stephen Colbert wants it all](support/giveittome.gif)\n",
    "\n",
    "How hard will it be to grab that big bunch of narrative stuff? In most browsers, you can right-click (maybe around the \"Name\") entry in the biography) and left-click on Inspect. You should see something like this.\n",
    "\n",
    "![Output of HTML inspector](support/tableinspect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the right side we see the main part of this demographic information is all in a HTML table: * &lt;table class=\"table\\_deathrow indent\"&gt; *\n",
    "\n",
    "This is good. We can work with this. Move your cursor through the inspection area and you'll see different rows highlight. Every row of the table -- *&lt;tr&gt;* -- is a row in what you're seeing. The two sides of that table are separated by *&lt;td&gt;* tags, or table data tags, the HTML marker for a cell. This is very good.\n",
    "\n",
    "As long as all your scraping projects can go this well, you'll be fortunate. Will you?\n",
    "\n",
    "![Image of hand showing sticker of Stop and Pray. Source: https://www.pexels.com/photo/photography-of-a-persons-hand-with-stop-signage-823301/](support/stopandpray.jpg)\n",
    "\n",
    "\n",
    "Yeah, no.\n",
    "\n",
    "Let's get reoriented: The stuff off the main page is an index to the more detailed subpages. So we'll need to scrape that main page first, get some of that information, and then start scraping the subpages and get more. And along the way, we'll probably need to look at other pages including the final statement and download the photos.\n",
    "\n",
    "So where do we start? We start at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic scraper setup\n",
    "\n",
    "So when you're scraping web pages, you need something to download web pages. Here, we'll use the great _requests_ library:\n",
    "\n",
    "_import requests_\n",
    "\n",
    "We'll need something that can parse the web pages, or break them into understandable chunks that you can maneuver through. We'll use the splendid _PyQuery_ library. This one's a little odd to set up; it breaks Python tradition by having mixed case for the main module, and that's also annoying to type. You can run a raw import statement on it, but each time you'd have to type _pyquery.PyQuery(somethingsomething)_ and at that point you might as just try to cuddle a honey badger. Let's get in the habit of a different import statement that will mean we need a lot less typing. In fact, let's just use _pq_ to mean _pyquery.PyQuery_. If you use PyQuery, just copy-paste this line every time until you have it memorized. After that, it's so much easier.\n",
    "\n",
    "_from pyquery import PyQuery as pq_\n",
    "\n",
    "We'll want to do **something** with our scraped data. Chances are, even if you keep processing it directly in Python, you'll probably want to save some snapshots to disk. And chances are, the CSV format is the one you'll want. So, let's add one more module.\n",
    "\n",
    "_import csv_\n",
    "\n",
    "You'll almost certainly need more modules as you go on -- maybe something to change the formatting of the dates, say. But you can add what you need later.\n",
    "\n",
    "You can have your own style. I tend to put external dependencies in their own section at the very top of the file, and built-in module statements following a blank line, like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests   # external dependency\n",
    "from pyquery import PyQuery as pq   # external dependency\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start scraping web pages. Where do we start? Well, we know what URL we're starting with. And we know requests is used to get stuff ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosturl = \"http://localhost/www.tdcj.texas.gov/death_row/dr_executed_offenders.html\"\n",
    "r = requests.get(hosturl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!doctype html>\\n<html lang=\"en-US\"><!-- InstanceBegin template=\"/Templates/generic_inside.dwt\" codeOutsideHTMLIsLocked=\"false\" -->\\n<head>\\n<meta charset=\"utf-8\">\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n<!-- stylesheet: global -->\\n<link rel=\"stylesheet\" href=\"../stylesheets/global.css\">\\n<!-- stylesheet: page-specific -->\\n<link rel=\"stylesheet\" href=\"../stylesheets/content.css\">\\n<link rel=\"stylesheet\" href=\"../stylesheets/menu_style.css\">\\n<!-- InstanceBeginEditable name=\"stylesheets\" -->\\n\\n<!-- InstanceEndEditable -->\\n<!-- jQuery library (if CDN fails, use local copy) -->\\n<script type=\"text/javascript\" src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js\"></script>\\n<script type=\"text/javascript\"> window.jQuery || document.write(\\'<script src=\"../javascripts/jquery.min.js\"><\\\\/script>\\') </script>\\n<!-- javascripts -->\\n<script type=\"text/javascript\" src=\"../javascripts/google_analytics.js\"></script>\\n<script type=\"text/javascript\" src=\"https://www.tdcj.texas.gov/javascripts/google_analytics_all.js\"></script>\\n<script type=\"text/javascript\" src=\"../javascripts/google_search.js\"></script>\\n<script type=\"text/javascript\" src=\"../javascripts/google_translate.js\"></script>\\n<!-- other headers -->\\n<!-- InstanceBeginEditable name=\"doctitle\" -->\\n<title>Death Row Information</title>\\n<!-- InstanceEndEditable -->\\n<!-- InstanceBeginEditable name=\"meta_description\" -->\\n<meta name=\"Description\" content=\"Texas Department of Criminal Justice.\">\\n<!-- InstanceEndEditable -->\\n<!--[if lt IE 9]>\\n<link rel=\"stylesheet\" href=\"/stylesheets/global_ie.css\">\\n<link rel=\"stylesheet\" href=\"/stylesheets/content_ie.css\">\\n<script src=\"/javascripts/html5shiv-printshiv.min.js\"></script>\\n<![endif]-->\\n</head>\\n\\n<body>\\n<div id=\"skiptocontent\"><a href=\"dr_executed_offenders.html#maincontent\">skip to main content</a></div>\\n<!-- top header banners -->\\n<header>\\n\\t<!-- alert banner -->\\n    <section id=\"alert_top\">\\n        <a href=\"http://www.tdcj.texas.gov/alert/index.html\">ALE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what we've downloaded, just part of it\n",
    "r.content[:2000]\n",
    "# Yep, we have a web page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's get the actual stuff, and we'll put it in a variable called html.\n",
    "html = r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning the first scrape\n",
    "Let's take a look at the main page code in our browser, either through the right-click-Left-click-on-Inspect or View Source(1). The code we really want to find is in here a bit:\n",
    "\n",
    "*(1) Right-click-left-click-on-inspect will bite you at some point. View Source is much safer because JavaScript, but less convenient.*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<h1>Death Row Information</h1>\n",
    "<h2>Executed Offenders</h2>\n",
    "<div class=\"overflow\">\n",
    "<table class=\"tdcj_table indent\" style=\"width: 98%\">\n",
    "    <caption>Executed Offenders</caption>\n",
    "  <tr>\n",
    "    <th style=\"text-align: center\" scope=\"col\">Execution</th>\n",
    "    <th style=\"text-align: center; width: 16%\" scope=\"col\">Link</th>\n",
    "    <th style=\"text-align: center; width: 13%\" scope=\"col\">Link</th>\n",
    "    <th style=\"text-align: center\" scope=\"col\">Last Name</th>\n",
    "    <th style=\"text-align: center\" scope=\"col\">First Name</th>\n",
    "    <th style=\"text-align: center; width: 7%\" scope=\"col\">TDCJ<br>Number</th>\n",
    "    <th style=\"text-align: center\" scope=\"col\">Age</th>\n",
    "    <th style=\"text-align: center\" scope=\"col\">Date</th>\n",
    "    <th style=\"text-align: center\" scope=\"col\">Race</th>\n",
    "    <th style=\"text-align: center\" scope=\"col\">County</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align: center\">558</td>\n",
    "    <td style=\"text-align: center\"><a href=\"dr_info/brazielalvin.html\" title=\"Offender Information for Joseph Garcia\">Offender Information</a></td>\n",
    "    <td style=\"text-align: center\"><a href=\"dr_info/brazielalvinlast.html\" title=\"Last Statement of Joseph Garcia\">Last Statement</a></td>\n",
    "    <td style=\"text-align: center\">Braziel, Jr.</td>\n",
    "    <td style=\"text-align: center\">Alvin</td>\n",
    "    <td style=\"text-align: center\">999393</td>\n",
    "    <td style=\"text-align: center\">43</td>\n",
    "    <td style=\"text-align: center\">12/11/2018</td>\n",
    "    <td style=\"text-align: center\">Black</td>\n",
    "    <td style=\"text-align: center\">Dallas</td>\n",
    "  </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What can we tell from this? There's a couple headers, whatever. Fine. But there's a table with a class of *tdcj\\_table* where the good stuff is. The first row of the table is its headers, with everything inside *th* cells. Beneath that is our first row of real data, contained in *td* cells. Sometimes we just want the text, like *Alvin*. Sometimes we're looking for the URLs that aren't actually text, like the link.\n",
    "\n",
    "So what's a sensible data structure here? We know we're going to have to roll up at least one subpage to get more details. So we need a data structure that lets us access the same stuff easily, and here's where Python is handy with something called a dictionary. It provides access by name to some data, often a single value but sometimes a whole thing. For example, you might see a dictionary pointing to just a single text string, or a list of things:\n",
    "\n",
    "*presidents[1] = \"George Washington\"*\n",
    "\n",
    "*food['fruits'] = ['apple', 'orange', 'lemon', 'lime', 'tomato']*\n",
    "\n",
    "When I'm scraping, I'm almost always putting each row of data into its own dictionary, with a particular type called OrderedDict, which keeps the order. So in this case, we're looking for, like:\n",
    "\n",
    "*mydictionary = {'first name': \"Alvin\", \"last name\": \"Braziel Jr.*}\n",
    "\n",
    "It would make sense to put each person's dictionary of data into one big dictionary that holds them. But to do that, we need a key, a unique value to refer to one person.\n",
    "\n",
    "As we've seen, the names of Texas' executed inmates don't even match from the index page to the subpage, and it's entirely possible Texas, given enough time, would execute several people named Robert Smith. So don't go by name. However, that inmate identifier, the \"TDJC Number,\" is assigned to single person, and presumably even Texas would never execute a person more than once.\n",
    "\n",
    "Presumably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "masterdict = OrderedDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember before? ... *&lt;table class=\"tdcj_table indent\" ...* That's the good stuff. Let's try getting it.\n",
    "\n",
    "In PyQuery, the first thing you put in is the first, big hunk of HTML. After that, you're looking for a tag, like \"table\" or \"td\" or \"a\". You can use a dot to show a class, like *p.narrative*, to find the code wrapped in something like *&lt;p class=\"narrative\"&gt;*. You can use a # to show a name, like *p#beginning*, which would look for *&lt;p id=\"beginning\"&gt;*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq(html)(\"table.tdcj_table\")   # Pick out the table with the good stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    <caption>Executed Offenders</caption>\\n  <tr>\\n    <th style=\"text-align: center\" scope=\"col\">Execution</th>\\n    <th style=\"text-align: center; width: 16%\" scope=\"col\">Link</th>\\n    <th style=\"text-align: center; width: 13%\" scope=\"col\">Link</th>\\n    <th style=\"text-align: center\" scope=\"col\">Last Name</th>\\n    <th style=\"text-align: center\" scope=\"col\">First Name</th>\\n    <th style=\"text-align: center; width: 7%\" scope=\"col\">TDCJ<br/>Number</th>\\n    <th style=\"text-align: center\" scope=\"col\">Age</th>\\n    <th style=\"text-align: center\" scope=\"col\">Date</th>\\n    <th style=\"text-align: center\" scope=\"col\">Race</th>\\n    <th style=\"text-align: center\" scope=\"col\">County</th>\\n  </tr>\\n  <tr>\\n    <td style=\"text-align: center\">558</td>\\n    <td style=\"text-align: center\"><a href=\"dr_info/brazielalvin.html\" title=\"Offender Information for Joseph Garcia\">Offender Information</a></td>\\n    <td style=\"text-align: center\"><a href=\"dr_info/brazielalvinlast.html\" title=\"Last Statement of Joseph Garcia\">Last Statement</a></td>\\n    <td style=\"text-align: center\">Braziel, Jr.</td>\\n    <td style=\"text-align: center\">Alvin</td>\\n    <td style=\"text-align: center\">999393</td>\\n    <td style=\"text-align: center\">43</td>\\n    <td style=\"text-align: center\">12/11/2018</td>\\n    <td style=\"text-align: center\">Black</td>\\n    <td style=\"text-align: center\">Dallas</td>\\n  </tr>\\n  <tr>\\n    <td style=\"text-align: center\">557</td>\\n    <td style=\"text-align: center\"><a href=\"dr_info/garciajoseph.html\" title=\"Offender Information for Joseph Garcia\">Offender Information</a></td>\\n    <td style=\"text-align: center\"><a href=\"dr_info/garciajosephlast.html\" title=\"Last Statement of Joseph Garcia\">Last Statement</a></td>\\n    <td style=\"text-align: center\">Garcia</td>\\n    <td style=\"text-align: center\">Joseph</td>\\n    <td style=\"text-align: center\">999441</td>\\n    <td style=\"text-align: center\">47</td>\\n    <td style=\"text-align: center\">12/04/2018</td>\\n    <td style=\"text-align: center\">Hispanic</td>\\n    <td '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the top:\n",
    "table.html()[:2000]\n",
    "# Yep, we have our table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's flip back to that web page again and just ... look. In Python, you start counting from 0. So table row 0 is going to be the headers; our good data begins at row 1. Our first column of real data is the execution, will be in table data cell 0, and we want the text ... You know what? Let's just sketch this out.\n",
    "* cell 0, text to ExecutionNo.\n",
    "* cell 1, URL, to BioURL\n",
    "* cell 2, URL, to Statement\n",
    "* cell 3, text, to LastName\n",
    "* cell 4, text, to FirstName\n",
    "* cell 5, text, to InmateNumber\n",
    "* cell 6, text, to Age\n",
    "* cell 7, text, to ExecutionDate\n",
    "* cell 8, text, to Race\n",
    "* cell 9, text, to County\n",
    "\n",
    "We should maybe fiddle with the order. Maybe something like this.\n",
    "\n",
    "* cell 5, text, to InmateNumber\n",
    "* cell 0, text to ExecutionNo.\n",
    "* cell 3, text, to LastName\n",
    "* cell 4, text, to FirstName\n",
    "* cell 6, text, to Age\n",
    "* cell 7, text, to ExecutionDate\n",
    "* cell 8, text, to Race\n",
    "* cell 9, text, to County\n",
    "* cell 1, URL, to BioURL\n",
    "* cell 2, URL, to Statement\n",
    "\n",
    "The URLs are going to be very important to us for the scrape, but they'll be near-worthless to us in the spreadsheet we want to build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558\n",
      "557\n",
      "556\n",
      "555\n",
      "554\n"
     ]
    }
   ],
   "source": [
    "# Let's try getting the execution number. Our HTML table is stored in the cunningly named \"table\" variable.\n",
    "# And we want to skip the first row, right? Let's just iterate beginning at the second row, which in Python is 1.\n",
    "# We can cheat and try like 5 rows at a time.\n",
    "\n",
    "for row in pq(table)(\"tr\")[1:6]:  # Pick up first five rows of real data, skipping header row\n",
    "    print(pq(row)(\"td\")[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('InmateNo', '999393'), ('ExecutionNo', '558'), ('LastName', 'Braziel, Jr.'), ('FirstName', 'Alvin'), ('Age', '43'), ('ExecutionDate', '12/11/2018'), ('Race', 'Black'), ('County', 'Dallas')])\n",
      "OrderedDict([('InmateNo', '999441'), ('ExecutionNo', '557'), ('LastName', 'Garcia'), ('FirstName', 'Joseph'), ('Age', '47'), ('ExecutionDate', '12/04/2018'), ('Race', 'Hispanic'), ('County', 'Dallas')])\n",
      "OrderedDict([('InmateNo', '999062'), ('ExecutionNo', '556'), ('LastName', 'Ramos'), ('FirstName', 'Robert'), ('Age', '64'), ('ExecutionDate', '11/14/2018'), ('Race', 'Hispanic'), ('County', 'Hidalgo')])\n",
      "OrderedDict([('InmateNo', '999381'), ('ExecutionNo', '555'), ('LastName', 'Acker'), ('FirstName', 'Daniel'), ('Age', '46'), ('ExecutionDate', '9/27/2018'), ('Race', 'White'), ('County', 'Hopkins')])\n",
      "OrderedDict([('InmateNo', '999351'), ('ExecutionNo', '554'), ('LastName', 'Clark'), ('FirstName', 'Troy'), ('Age', '51'), ('ExecutionDate', '9/26/2018'), ('Race', 'White'), ('County', 'Smith')])\n"
     ]
    }
   ],
   "source": [
    "# OK, we have our execution numbers. You know what? I really don't want to type that \"pq\" stuff eight times over.\n",
    "# So we can  build a stupid lil function. But ...\n",
    "# If I were a dreamer, but then again, no.\n",
    "# Let's save the routine for later and just copy paste. And we'll want to start storing stuff in masterdict.\n",
    "# Key it to the inmate number. Keep it in an OrderedDict. OK, fine.\n",
    "# My standard has been that a **row** comes in, and a **line** goes out. No real rhyme or reason, but ...\n",
    "# let's keep with it.\n",
    "\n",
    "for row in pq(table)(\"tr\")[1:6]:   # Pick off first five lines of real data\n",
    "    line = OrderedDict()\n",
    "    line['InmateNo'] = pq(row)(\"td\")[5].text\n",
    "    line['ExecutionNo'] = pq(row)(\"td\")[0].text\n",
    "    line['LastName'] = pq(row)(\"td\")[3].text\n",
    "    line['FirstName'] = pq(row)(\"td\")[4].text\n",
    "    line['Age'] = pq(row)(\"td\")[6].text\n",
    "    line['ExecutionDate'] = pq(row)(\"td\")[7].text\n",
    "    line['Race'] = pq(row)(\"td\")[8].text\n",
    "    line['County'] = pq(row)(\"td\")[9].text\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, we're much of the way there. We still have a leash on to show only the first five rows of data,\n",
    "# that Python slicing of [1:6].\n",
    "# We're missing the critical URLs, though. Let's look at the last row we pulled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr>\n",
      "    <td style=\"text-align: center\">554</td>\n",
      "    <td style=\"text-align: center\"><a href=\"dr_info/clarktroy.html\" title=\"Offender Information for Troy Clark\">Offender Information</a></td>\n",
      "    <td style=\"text-align: center\"><a href=\"dr_info/clarktroylast.html\" title=\"Last Statement of Troy Clark\">Last Statement</a></td>\n",
      "    <td style=\"text-align: center\">Clark</td>\n",
      "    <td style=\"text-align: center\">Troy</td>\n",
      "    <td style=\"text-align: center\">999351</td>\n",
      "    <td style=\"text-align: center\">51</td>\n",
      "    <td style=\"text-align: center\">9/26/2018</td>\n",
      "    <td style=\"text-align: center\">White</td>\n",
      "    <td style=\"text-align: center\">Smith</td>\n",
      "  </tr>\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(pq(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# If we grab just the text of this thing, we're not going to get much:\n",
    "print(pq(row)(\"td\")[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method PyQuery.text of [<a>]>\n"
     ]
    }
   ],
   "source": [
    "# Wait, why none? Because there's no raw text in the cell. What text there is is wrapped inside the *a* tag.\n",
    "# Let's feed it into another round of PyQuery:\n",
    "print(pq(pq(row)(\"td\")[1])(\"a\").text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Well, crap.\n",
    "\n",
    "\"Bound method\" means it's looking for something like a function, so throw in some ()s.\n",
    "\n",
    "Is this a predictable behavior in PyQuery? Not that I can figure out. But if you see \"bound method,\" try extra parenthesesesies. Keep working your problem.\n",
    "\n",
    "![Clown wondering how stuff works](support/magnets.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offender Information\n"
     ]
    }
   ],
   "source": [
    "print(pq(pq(row)(\"td\")[1])(\"a\").text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we don't actually want that text. What we want is the URL, which is stored as an **attribute** of the *a* tag. Right?\n",
    "\n",
    "*&lt;a href=\"something\"&gt;*\n",
    "\n",
    "\n",
    "Other attributes include things like *class* and *id* tags. But here's how to grab that *href* attribute of the *a* tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr_info/clarktroy.html\n"
     ]
    }
   ],
   "source": [
    "print(pq(pq(row)(\"td\")[1])(\"a\").attr(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dr_info/clarktroy.html**? What the hell kind of URL is that? Well, it's a relative URL. Starting from the directory you're in now, it's going to look inside *dr_info* for a file named clarktroy.html. We started off here:\n",
    "http://localhost/www.tdcj.texas.gov/death_row/dr_executed_offenders.html\n",
    "\n",
    "So *dr\\_executed\\_offenders.html* is a page inside *death\\_row* ... so let's start gluing this together.\n",
    "\n",
    "http://localhost/www.tdcj.texas.gov/death_row/ + dr_info/clarktroy.html ... becomes:\n",
    "\n",
    "http://localhost/www.tdcj.texas.gov/death_row/dr_info/clarktroy.html\n",
    "\n",
    "Open it. We're in business!\n",
    "\n",
    "Let's set a variable we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopagebase = \"http://localhost/www.tdcj.texas.gov/death_row/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much did we just skip around?\n",
    "\n",
    "Well, not too much. We were figuring out how to start getting at our subpages, but we're not going to scrape them just yet. Let's take a look. We have masterdict. We have almost the entirety of the main page scraper. Let's finish it.\n",
    "\n",
    "Before we were limiting Python to looking at rows 1 to 6 with *[1:6]*. That skipped the header row and then got us five rows of actual usable data. Let's take that off.\n",
    "\n",
    "We also now know we need to set that variable to make sense of our partial URLs.\n",
    "\n",
    "We also know we need to get a proper URL for all the last statements.\n",
    "\n",
    "So if this gets us the URL from the second column:\n",
    "\n",
    "*print(pq(pq(row)(\"td\")[1])(\"a\").attr(\"href\"))*\n",
    "\n",
    "maybe this will get us the URL for the third column:\n",
    "\n",
    "*print(pq(pq(row)(\"td\")[2])(\"a\").attr(\"href\"))*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr_info/clarktroylast.html\n"
     ]
    }
   ],
   "source": [
    "print(pq(pq(row)(\"td\")[2])(\"a\").attr(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost/www.tdcj.texas.gov/death_row/dr_info/clarktroylast.html\n"
     ]
    }
   ],
   "source": [
    "# Promising. Let's check out if that same URL prefix still works:\n",
    "print(biopagebase + pq(pq(row)(\"td\")[2])(\"a\").attr(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, now what?\n",
    "\n",
    "![Guy waiting](support/bride.gif)\n",
    "\n",
    "From a few sections up, we've ... figured out what we need to scrape the first section.\n",
    "\n",
    "Except we also forgot to actually, you know, save this data somewhere. So let's save it all in *masterdict*, with the key being the inmate number. The value will be the entire row/line of data.\n",
    "\n",
    "We also need to scrape the full URLs for the subpages, so ... Let's just piece it together.\n",
    "\n",
    "Remember before we were looking at rows 1 to 6, skipping the header row. Now, we want to look from row 1 to the end. Scrape it all! That syntax will be *[1:]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopagebase = \"http://localhost/www.tdcj.texas.gov/death_row/\"\n",
    "for row in pq(table)(\"tr\")[1:]:   # Skip that header row, get everything else\n",
    "    line = OrderedDict()\n",
    "    line['InmateNo'] = pq(row)(\"td\")[5].text\n",
    "    line['ExecutionNo'] = pq(row)(\"td\")[0].text\n",
    "    line['LastName'] = pq(row)(\"td\")[3].text\n",
    "    line['FirstName'] = pq(row)(\"td\")[4].text\n",
    "    line['Age'] = pq(row)(\"td\")[6].text\n",
    "    line['ExecutionDate'] = pq(row)(\"td\")[7].text\n",
    "    line['Race'] = pq(row)(\"td\")[8].text\n",
    "    line['County'] = pq(row)(\"td\")[9].text\n",
    "    line['BioURL'] = biopagebase + pq(pq(row)(\"td\")[1])(\"a\").attr(\"href\")\n",
    "    line['StatementURL'] = biopagebase + pq(pq(row)(\"td\")[2])(\"a\").attr(\"href\")\n",
    "    masterdict[line['InmateNo']] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines scraped: 558\n"
     ]
    }
   ],
   "source": [
    "# Wait, did that just work?\n",
    "print(f\"Lines scraped: {len(masterdict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('InmateNo', '592'), ('ExecutionNo', '1'), ('LastName', 'Brooks, Jr.'), ('FirstName', 'Charlie'), ('Age', '40'), ('ExecutionDate', '12/07/1982'), ('Race', 'Black'), ('County', 'Tarrant'), ('BioURL', 'http://localhost/www.tdcj.texas.gov/death_row/dr_info/brookscharlie.html'), ('StatementURL', 'http://localhost/www.tdcj.texas.gov/death_row/dr_info/brookscharlielast.html')])\n"
     ]
    }
   ],
   "source": [
    "# Did we just get it all?\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for the subpages\n",
    "\n",
    "Yeah, we're not done yet. We want to at least figure out how to scrape those subpages. So ... Let's do it. We can traverse through *masterdict* and pick out *BioURL* from each of the entries inside. Then we just open up those URLs and start scraping.\n",
    "\n",
    "Except. .. We don't need to scrape 558 of these things all at once while testing. Let's just keep using our last *line* entry  and see what we've got.\n",
    "\n",
    "Let's take a look at that last person's BioURL:\n",
    "http://localhost/www.tdcj.texas.gov/death_row/dr_info/brookscharlie.html\n",
    "\n",
    "At first blush, the biography seems to match the newest guy. Missing a photo. Some stuff is recorded kind of strangely. But ... Let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BioURL = line['BioURL']\n",
    "r = requests.get(BioURL)\n",
    "html = r.content    # We can recycle \"html\" as our main variable because we're all done scraping the initial page.\n",
    "                    # If we weren't, this would be ... bad.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here there be dragons\n",
    "\n",
    "Above, we just recycled variables called *r* and *html*. We can do this because we've completed our scrape of the main page. But if we went row-by-row on the main page and then scraped the BioURL pages in each row, our code would break in horrible ways. So ... mind the gap.\n",
    "\n",
    "Let's go take a look at what we've got. From that bio page, it looks like the main table is somewhere around here:\n",
    "\n",
    "`...\n",
    "    <h1>Death Row Information</h1>\n",
    "    <h2>Offender Information</h2>\n",
    "    <table class=\"table_deathrow indent\">\n",
    "      <tr>\n",
    "        <td rowspan=\"7\" style=\"vertical-align: top\">Photo not available</td>\n",
    "        <td style=\"vertical-align: top\" class=\"table_deathrow_bold_align_right\">Name</td>\n",
    "        <td style=\"vertical-align: top\" class=\"table_deathrow_align_left\">Brooks, Charlie Jr.</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"vertical-align: top\" class=\"table_deathrow_bold_align_right\">TDCJ Number</td>\n",
    "        <td style=\"vertical-align: top\" class=\"table_deathrow_align_left\">592</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"vertical-align: top\" class=\"table_deathrow_bold_align_right\">Date of Birth</td>\n",
    "        <td style=\"vertical-align: top\" class=\"table_deathrow_align_left\">9/1/1942</td>\n",
    "    ...\n",
    "`\n",
    "\n",
    "So, we can recycle our *table* variable again. We're looking for a tag of *table* with a class of *table_deathrow*.\n",
    "\n",
    "And here the layout is kind of ... weird, right? We have no header row.\n",
    "\n",
    "Our first row has a bunch of elements in it; there's one table data cell that should hold the photo, but it's actually set to span seven columns. And then there's the description of \"Name\" and the actual name, for a total of nine columns. Then the next line shows ... two columns.\n",
    "\n",
    "We could sit here and write special handling for the first row, but then we're repeating. What we can say safely is really simple:\n",
    "\n",
    "The description of the data we want is always in the second-to-last column.\n",
    "\n",
    "The actual data we want is in the last column. So let's just proceed that way, and see what we can come up with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq(html)(\"table.table_deathrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Brooks, Charlie Jr.\n",
      "TDCJ Number: 592\n",
      "Date of Birth: 9/1/1942\n",
      "Date Received: 4/25/1978\n",
      "Age (when    Received): 35\n",
      "Education Level (Highest Grade Completed): 12\n",
      "Date of Offense: 12/14/1976\n",
      "Age (at the time of Offense): 34\n",
      "County: Tarrant\n",
      "Race: Black\n",
      "Gender: Male\n",
      "Hair Color: Black\n",
      "Height: 5' 9\"\n",
      "Weight: 150\n",
      "Eye Color: mar (according to DPS records)\n",
      "Native County: Tarrant\n",
      "Native State: Texas\n"
     ]
    }
   ],
   "source": [
    "for row in pq(table)(\"tr\"):\n",
    "    description = pq(row)(\"td\")[-2].text\n",
    "    data = pq(row)(\"td\")[-1].text\n",
    "    print(f\"{description}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('InmateNo', '592'), ('ExecutionNo', '1'), ('LastName', 'Brooks, Jr.'), ('FirstName', 'Charlie'), ('Age', '40'), ('ExecutionDate', '12/07/1982'), ('Race', 'Black'), ('County', 'Tarrant'), ('BioURL', 'http://localhost/www.tdcj.texas.gov/death_row/dr_info/brookscharlie.html'), ('StatementURL', 'http://localhost/www.tdcj.texas.gov/death_row/dr_info/brookscharlielast.html'), ('Name', 'Brooks, Charlie Jr.'), ('TDCJ Number', '592'), ('Date of Birth', '9/1/1942'), ('Date Received', '4/25/1978'), ('Age (when    Received)', '35'), ('Education Level (Highest Grade Completed)', '12'), ('Date of Offense', '12/14/1976'), ('Age (at the time of Offense)', '34'), ('Gender', 'Male'), ('Hair Color', 'Black'), ('Height', '5\\' 9\"'), ('Weight', '150'), ('Eye Color', 'mar (according to DPS records)'), ('Native County', 'Tarrant'), ('Native State', 'Texas')])\n"
     ]
    }
   ],
   "source": [
    "# now what? Well, ... Let's add it to our data. We can actually just use their field descriptions as our data identifier.\n",
    "for row in pq(table)(\"tr\"):\n",
    "    description = pq(row)(\"td\")[-2].text\n",
    "    data = pq(row)(\"td\")[-1].text\n",
    "    line[description] = data\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The road is clear. Move out!\n",
    "\n",
    "We've now got something that should get us most of the biographical data from these subpages. Let's bring it all together, and scrape a few hundred pages. And we just start writing and ...\n",
    "\n",
    "<code>\n",
    "for InmateNo in masterdict:\n",
    "    line = masterdict[InmateNo]  # Get that whole person-level dictionary\n",
    "    r = requests.get(line['BioURL'])   # Get their biography page\n",
    "    html = r.content\n",
    "    table = pq(html)(\"table.table_deathrow\")\n",
    "    for row in pq(table)(\"tr\"):\n",
    "        description = pq(row)(\"td\")[-2].text\n",
    "        data = pq(row)(\"td\")[-1].text\n",
    "        line[description] = data\n",
    "    # Now let's write the line back to masterdict to save our changes\n",
    "    masterdict[InmateNo] = line    `\n",
    "</code>    \n",
    "\n",
    "\n",
    "### NO. No. No. Just, no.\n",
    "\n",
    "OK, it was that easy to write the rest of that part of the scraper, but we're leaving a bunch of great data on the table.\n",
    "\n",
    "Remember the first person we looked at?\n",
    "\n",
    "http://localhost/www.tdcj.texas.gov/death_row/dr_info/brazielalvin.html\n",
    "\n",
    "Photo. We didn't write anything to handle photo. And while that biobox looks the same -- maybe, there's a lot to keep track of -- there's a bunch of stuff below that whole biobox. So let's chill for a second and look at Alvin Braziel.\n",
    "\n",
    "`<table class=\"table_deathrow indent\">\n",
    "  <tr>\n",
    "    <td rowspan=\"7\" style=\"vertical-align: top\"><img src=\"brazielalvin2.jpg\" alt=\"Picture of Offender\" /></td>`\n",
    "    \n",
    "But we saw with the other person:\n",
    "\n",
    "`        <td rowspan=\"7\" style=\"vertical-align: top\">Photo not available</td>\n",
    "`\n",
    "\n",
    "So ... not everyone will have an image. And we have that fragmentary URL again. Maybe we can take that old *biopagebase* URL fragment and tack it on and see if that works for the photo:\n",
    "\n",
    "http://localhost/www.tdcj.texas.gov/death_row/brazielalvin2.jpg\n",
    "\n",
    "Nope, that doesn't work. But remember when we got the local BioURL we were seeing addresses like *dr_info/clarktroylast.html*\n",
    "\n",
    "That means when we're actually looking at the page, we're already in the *dr_info* folder. If we just have a reference to *brazielalvin2.jpg*, it's in that same folder.\n",
    "\n",
    "http://localhost/www.tdcj.texas.gov/death_row/dr_info/brazielalvin2.jpg\n",
    "\n",
    "And **that** works. So let's set this:\n",
    "\n",
    "photobase = \"http://localhost/www.tdcj.texas.gov/death_row/dr_info/\"\n",
    "\n",
    "Now we've figured out the URL scheme. How do we get at the photo URL? Well, it's going to be in the first *td* tag of *table.table_deathrow*.\n",
    "\n",
    "Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td rowspan=\"7\" style=\"vertical-align: top\"><img src=\"brazielalvin2.jpg\" alt=\"Picture of Offender\"/></td>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "r = requests.get(\"http://localhost/www.tdcj.texas.gov/death_row/dr_info/brazielalvin.html\")\n",
    "html = r.content\n",
    "photobase = \"http://localhost/www.tdcj.texas.gov/death_row/dr_info/\"\n",
    "photocell = pq(pq(html)(\"table.table_deathrow\"))(\"td\")[0]\n",
    "print(pq(photocell))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success! Ish. \n",
    "\n",
    "So we want to look for an img tag inside of all that mess.\n",
    "\n",
    "And if we find the image tag ...\n",
    "\n",
    "We want to extract the SRC attribute\n",
    "\n",
    "And if we have that SRC attribute, we want to prepend that \"photobase\" URL before it.\n",
    "\n",
    "Feel like you're going in circles? Try this: https://en.wikipedia.org/wiki/If_You_Give_a_Mouse_a_Cookie#Plot\n",
    "\n",
    "But we can do this. Put it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "photocellURL = pq(pq(pq(html)(\"table.table_deathrow\"))(\"td\")[0])(\"img\").attr(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if photocellURL:   # If we've found that img src tag ...\n",
    "    photocellURL = photobase + photocellURL\n",
    "else:\n",
    "    photocellURL = \"\"\n",
    "line['PhotoURL'] = photocellURL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### But wait! There's more!\n",
    "\n",
    "That detail page has a bunch more stuff:\n",
    "\n",
    "`...\n",
    "    <p><span class=\"bold\">Prior Occupation</span><br />\n",
    "    Laborer </p>\n",
    "    <p> <span class=\"bold\">Prior Prison Record</span><br />\n",
    "    #792374  on a 5 year sentence from Dallas   County for 1 count of  sexual assault of a child. (Current offense was committed prior to the offender  being incarcerated for the sexual assault conviction.) </p>\n",
    "    <p> <span class=\"bold\">Summary of Incident</span><br />\n",
    "    On  9/21/1993 at 9:00 p.m. in Mesquite,  Braziel approached a newlywed couple walking on a jogging trail of a community  college. Braziel demanded money. When it was discovered that neither of the two  had any money in their possession, Braziel shot the 27 year old white male,  resulting in his death. Braziel then sexually assaulted the 23 year old white  female. Braziel linked to the crime in January 2001 when his DNA was found to  match the DNA taken from the female victim. </p>\n",
    "    <p> <span class=\"bold\">Co-Defendants</span><br />\n",
    "    None </p>\n",
    "    <p> <span class=\"bold\">Race and Gender of Victim</span><br />\n",
    "    White  male</p>\n",
    "...\n",
    "`\n",
    "\n",
    "So ... Let's grab it. In this case, we're **really** lucky -- these are the only *p* tags in the entire page. So inside of the *p* tag, there's a *span* tag with a description as text; and the data we want is directly part of the text of the *p* tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Occupation: Prior Occupation\n",
      "Laborer\n",
      "Prior Prison Record: Prior Prison Record\n",
      "#792374 on a 5 year sentence from Dallas County for 1 count of sexual assault of a child. (Current offense was committed prior to the offender being incarcerated for the sexual assault conviction.)\n",
      "Summary of Incident: Summary of Incident\n",
      "On 9/21/1993 at 9:00 p.m. in Mesquite, Braziel approached a newlywed couple walking on a jogging trail of a community college. Braziel demanded money. When it was discovered that neither of the two had any money in their possession, Braziel shot the 27 year old white male, resulting in his death. Braziel then sexually assaulted the 23 year old white female. Braziel linked to the crime in January 2001 when his DNA was found to match the DNA taken from the female victim.\n",
      "Co-Defendants: Co-Defendants\n",
      "None\n",
      "Race and Gender of Victim: Race and Gender of Victim\n",
      "White male\n"
     ]
    }
   ],
   "source": [
    "for graf in pq(html)(\"p\"):\n",
    "    data = pq(graf)(\"p\").text().strip()\n",
    "    description = pq(graf)(\"span\")[0].text.strip()\n",
    "    print(description + \": \" + data)\n",
    "    # line[description] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, shoot.\n",
    "\n",
    "We're getting the description as part of our data. OK. So PyQuery does have a way around this; we can ignore stuff in **child elements** like the *span* tag by looking only at *outerHtml*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Occupation: Prior Occupation\n",
      "Laborer\n",
      "Prior Prison Record: Prior Prison Record\n",
      "#792374 on a 5 year sentence from Dallas County for 1 count of sexual assault of a child. (Current offense was committed prior to the offender being incarcerated for the sexual assault conviction.)\n",
      "Summary of Incident: Summary of Incident\n",
      "On 9/21/1993 at 9:00 p.m. in Mesquite, Braziel approached a newlywed couple walking on a jogging trail of a community college. Braziel demanded money. When it was discovered that neither of the two had any money in their possession, Braziel shot the 27 year old white male, resulting in his death. Braziel then sexually assaulted the 23 year old white female. Braziel linked to the crime in January 2001 when his DNA was found to match the DNA taken from the female victim.\n",
      "Co-Defendants: Co-Defendants\n",
      "None\n",
      "Race and Gender of Victim: Race and Gender of Victim\n",
      "White male\n"
     ]
    }
   ],
   "source": [
    "for graf in pq(html)(\"p\"):\n",
    "    data = pq(pq(graf)(\"p\")).text().strip()\n",
    "    description = pq(graf)(\"span\")[0].text.strip()\n",
    "    print(description + \": \" + data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seriously?\n",
    "\n",
    "We're closer, but our \"data\" section contains our \"description\" from within the *span*. And this is getting annoying.\n",
    "\n",
    "So we can back this out slightly for a really stupid fix. text_content() sometimes works as a method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Race and Gender of Victim\\n  White  male'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graf.text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it. And that *br* tag comes through as *\\n*, a new line. So let's stick with just the text, we'll split on the *\\n*, and take the second half of this thing, strip off some white space, and this is ... just gonna look ugly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Occupation: Laborer\n",
      "Prior Prison Record: #792374  on a 5 year sentence from Dallas   County for 1 count of  sexual assault of a child. (Current offense was committed prior to the offender  being incarcerated for the sexual assault conviction.)\n",
      "Summary of Incident: On  9/21/1993 at 9:00 p.m. in Mesquite,  Braziel approached a newlywed couple walking on a jogging trail of a community  college. Braziel demanded money. When it was discovered that neither of the two  had any money in their possession, Braziel shot the 27 year old white male,  resulting in his death. Braziel then sexually assaulted the 23 year old white  female. Braziel linked to the crime in January 2001 when his DNA was found to  match the DNA taken from the female victim.\n",
      "Co-Defendants: None\n",
      "Race and Gender of Victim: White  male\n"
     ]
    }
   ],
   "source": [
    "for graf in pq(html)(\"p\"):\n",
    "    data = graf.text_content().split(\"\\n\")[1].strip()\n",
    "    description = pq(graf)(\"span\")[0].text.strip()\n",
    "    print(description + \": \" + data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ugly wins over broken!\n",
    "\n",
    "Now we can scrape everything from the main page and the bio subpage.\n",
    "\n",
    "You're free to scrape the last statement page on your own. The techniques you used already here will help you.\n",
    "\n",
    "Without further ado, let's piece this (almost) together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-36c9bbbc1212>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mgraf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mmasterdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInmateNo\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for InmateNo in masterdict:\n",
    "    line = masterdict[InmateNo]  # Get that whole person-level dictionary\n",
    "    r = requests.get(line['BioURL'])   # Get their biography page\n",
    "    html = r.content\n",
    "    table = pq(html)(\"table.table_deathrow\")\n",
    "    for row in pq(table)(\"tr\"):\n",
    "        description = pq(row)(\"td\")[-2].text\n",
    "        data = pq(row)(\"td\")[-1].text\n",
    "        line[description] = data\n",
    "    # Now let's write the line back to masterdict to save our changes\n",
    "    try:\n",
    "        photocellURL = pq(pq(pq(html)(\"table.table_deathrow\"))(\"td\")[0])(\"img\").attr(\"src\")\n",
    "        if photocellURL:   # If we've found that img src tag ...\n",
    "            photocellURL = photobase + photocellURL\n",
    "        else:\n",
    "            photocellURL = \"\"\n",
    "    except:\n",
    "        photocellURL = \"\"\n",
    "    line['PhotoURL'] = photocellURL\n",
    "    for graf in pq(html)(\"p\"):\n",
    "        data = graf.text_content().split(\"\\n\")[1].strip()\n",
    "        description = pq(graf)(\"span\")[0].text.strip()\n",
    "        line[description] = data\n",
    "    masterdict[InmateNo] = line    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x00\\x00\\x00d\\x00d\\x00\\x00\\xff\\xfe\\x00\\x1fLEAD Technologies Inc. V1.01\\x00\\xff\\xdb\\x00C\\x00\\x06\\x04\\x04\\x05\\x04\\x04\\x06\\x05\\x05\\x05\\x07\\x06\\x06\\x07\\t\\x10\\n\\t\\x08\\x08\\t\\x13\\x0e\\x0e\\x0b\\x10\\x17\\x14\\x18\\x18\\x16\\x14\\x16\\x16\\x19\\x1c$\\x1f\\x19\\x1b\"\\x1b\\x16\\x16 + \"&\\')))\\x18\\x1e-0,(0$()\\'\\xff\\xc4\\x00\\xd2\\x00\\x00\\x01\\x05\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\x10\\x00\\x02\\x01\\x03\\x03\\x02\\x04\\x03\\x05\\x05\\x04\\x04\\x00\\x00\\x01}\\x01\\x02\\x03\\x00\\x04\\x11\\x05\\x12!1A\\x06\\x13Qa\\x07\"q\\x142\\x81\\x91\\xa1\\x08#B\\xb1\\xc1\\x15R\\xd1\\xf0$3br\\x82\\t\\n\\x16\\x17\\x18\\x19\\x1a%&\\'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe1\\xe2\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf1\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9\\xfa\\xff\\xc0\\x00\\x0b\\x08\\x04g\\x03H\\x01\\x01\\x11\\x00\\xff\\xda\\x00\\x08\\x01\\x01\\x00\\x00?\\x00\\xfa\\xaa\\x8a)\\x19C\\x0c0\\x04z\\x1a\\x8c\\xda\\xc0P\\xa1\\x86=\\xa7\\xb6\\xd1\\x8a`\\xb1\\xb5\\xc9?f\\x88\\x93\\xd4\\x94\\x1c\\xd4\\x8b\\x04Hr\\x91\"\\x9fP\\xa0S\\xb6&s\\xb4g\\xe9Mkh\\\\\\xe5\\xa1\\x8d\\x88\\x18\\xe5A\\xa8_J\\xd3\\xdf\\xef\\xd8\\xdb6=bS\\xfd*\\t|9\\xa2\\xcf\\xfe\\xb7G\\xb1\\x93\\xfd\\xfbd?\\xd2\\xa9O\\xe0/\\t\\\\\\x82\\'\\xf0\\xbe\\x8f ?\\xde\\xb0\\x88\\xff\\x00\\xec\\xb5\\x9b7\\xc2\\x0f\\x87\\x93\\x92_\\xc1\\x1a\\tlcw\\xf6tY\\xff\\x00\\xd0k&\\xe7\\xe0W\\xc3\\x86\\x03>\\x0e\\xd2@\\xff'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost/www.tdcj.texas.gov/death_row/dr_info/_ramos.jpg\n"
     ]
    }
   ],
   "source": [
    "# This does not look like a useful HTML file, huh? Let's find out what's happening:\n",
    "print(line['BioURL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![You gotta be shitting me! image](support/ygbsm.gif)\n",
    "\n",
    "#### Yes, some of the information pages are ... pictures of an information page.\n",
    "\n",
    "Now what? Let's circle back. We're not parsing someone's typewritten form right now. So ... let's not. If there's no \"html\" in the filename, let's not try to parse the guts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-76edae13f336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PhotoURL'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphotocellURL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgraf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for InmateNo in masterdict:\n",
    "    line = masterdict[InmateNo]  # Get that whole person-level dictionary\n",
    "    bioURL = line['BioURL']\n",
    "    if \"html\" in bioURL:\n",
    "        r = requests.get(bioURL)   # Get their biography page\n",
    "        html = r.content\n",
    "        table = pq(html)(\"table.table_deathrow\")\n",
    "        for row in pq(table)(\"tr\"):\n",
    "            description = pq(row)(\"td\")[-2].text\n",
    "            data = pq(row)(\"td\")[-1].text\n",
    "            line[description] = data\n",
    "        # Now let's write the line back to masterdict to save our changes\n",
    "        try:\n",
    "            photocellURL = pq(pq(pq(html)(\"table.table_deathrow\"))(\"td\")[0])(\"img\").attr(\"src\")\n",
    "            if photocellURL:   # If we've found that img src tag ...\n",
    "                photocellURL = photobase + photocellURL\n",
    "            else:\n",
    "                photocellURL = \"\"\n",
    "        except:\n",
    "            photocellURL = \"\"\n",
    "        line['PhotoURL'] = photocellURL\n",
    "        for graf in pq(html)(\"p\"):\n",
    "            data = graf.text_content().split(\"\\n\")[1].strip()\n",
    "            description = pq(graf)(\"span\")[0].text.strip()\n",
    "            line[description] = data\n",
    "        masterdict[InmateNo] = line    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bioURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, well, huh. That didn't quite work out; some of these supplementary sections have more than one paragraph in the description.\n",
    "\n",
    "`...\n",
    "    <p><span class=\"bold\">Prior Occupation</span><br />\n",
    "    Wrecker  Driver/General Construction/Lineman/Laborer </p>\n",
    "    <p><span class=\"bold\">Prior Prison Record</span><br />\n",
    "    None </p>\n",
    "    <p><span class=\"bold\">Summary of Incident</span><br />\n",
    "    On  09/26/1986, in Harris County, Texas, AWFUL THING </p>\n",
    "    <p> On  04/16/1992 in Harris County, Texas, MORE AWFUL</p>\n",
    "    <p> On  10/19/1993, LET'S JUST STOP HERE</p>\n",
    "    ...\n",
    "    `\n",
    "OK, we can figure out how to serialize this, then, if we really want to. But we're also getting crazy into complexity. And maybe these details aren't quite so important.\n",
    "\n",
    "So what if we say, here's a paragraph tag. If there's no *span* inside of it, let's append something showing the record is incomplete and just not try to scrape the rest of it right now. If that's a bad move, we can rescrape later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for InmateNo in masterdict:\n",
    "    line = masterdict[InmateNo]  # Get that whole person-level dictionary\n",
    "    bioURL = line['BioURL']\n",
    "    if \"html\" in bioURL and \"no_info_available\" not in bioURL:  # !!!!!!!!!!!!!!!!!!!!!!! This broke too\n",
    "        r = requests.get(bioURL)   # Get their biography page\n",
    "        html = r.content\n",
    "        table = pq(html)(\"table.table_deathrow\")\n",
    "        for row in pq(table)(\"tr\"):\n",
    "            description = pq(row)(\"td\")[-2].text\n",
    "            data = pq(row)(\"td\")[-1].text\n",
    "            line[description] = data\n",
    "        # Now let's write the line back to masterdict to save our changes\n",
    "        try:\n",
    "            photocellURL = pq(pq(pq(html)(\"table.table_deathrow\"))(\"td\")[0])(\"img\").attr(\"src\")\n",
    "            if photocellURL:   # If we've found that img src tag ...\n",
    "                photocellURL = photobase + photocellURL\n",
    "            else:\n",
    "                photocellURL = \"\"\n",
    "        except:\n",
    "            photocellURL = \"\"\n",
    "        line['PhotoURL'] = photocellURL\n",
    "        for graf in pq(html)(\"p\"):\n",
    "            spanhere = pq(graf)(\"span\")\n",
    "            if spanhere:   # If this is a complete description + initial tag:\n",
    "                try:   # Yes, something else broke !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                    data = graf.text_content().split(\"\\n\")[1].strip()\n",
    "                    description = pq(graf)(\"span\")[0].text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                line[description] += \" ***INCOMPLETE**** \"\n",
    "            line[description] = data\n",
    "        masterdict[InmateNo] = line    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![This is fine meme](support/thisisfine.gif)\n",
    "\n",
    "The original code above broke, then broke again. Scraping of some pages goes smoothly. Sometimes, not so much, and your best-laid plans crumble. The more time you spend observing your data, the better your scrape will go.\n",
    "\n",
    "## But wait, there's more!\n",
    "\n",
    "We now have most of our scrapable data in one spot, but it's inconsistent; some have those details from the biography page; some do not. What we have to do is standardize, standardize, standardize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['InmateNo', 'ExecutionNo', 'LastName', 'FirstName', 'Age', 'ExecutionDate', 'Race', 'County', 'BioURL', 'StatementURL', 'Name', 'TDCJ Number', 'Date of Birth', 'Date Received', 'Age (when    Received)', 'Education Level (Highest Grade Completed)', 'Date of Offense', 'Age (at the time of Offense)', 'Gender', 'Hair Color', 'Height', 'Weight', 'Eye Color', 'Native County', 'Native State', 'PhotoURL', 'Prior Occupation', 'Prior Prison Record', 'Summary of Incident', 'Co-Defendants', 'Race and Gender of Victim', 'Age (when Received)', 'Summary of incident', 'Native Country']\n"
     ]
    }
   ],
   "source": [
    "# First, get a list of our keys, like our column headers.\n",
    "headers = []\n",
    "for InmateNo in masterdict:\n",
    "    row = masterdict[InmateNo]\n",
    "    for key in row.keys():\n",
    "        if key not in headers:\n",
    "            headers.append(key)\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That looks reasonable. Now, let's cycle through again and standardize:\n",
    "for InmateNo in masterdict:\n",
    "    row = masterdict[InmateNo]\n",
    "    line = OrderedDict()\n",
    "    for key in headers:\n",
    "        if key in row:\n",
    "            line[key] = row[key]\n",
    "        else:\n",
    "            line[key] = \"\"   # Give it a blank entry\n",
    "    \n",
    "    # Our data is now standardized but has not been saved.\n",
    "    masterdict[InmateNo] = line   # Copy over the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('report.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for InmateNo in masterdict:\n",
    "        line = masterdict[InmateNo]\n",
    "        writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
